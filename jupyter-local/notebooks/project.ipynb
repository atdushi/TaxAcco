{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Клиенты и счета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, DateType, DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "from src.main.etl import get_latest_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/08 17:17:00 WARN Utils: Your hostname, prodesk resolves to a loopback address: 127.0.1.1; using 192.168.31.239 instead (on interface eno1)\n",
      "23/05/08 17:17:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/maxim/spark-3.3.1-bin-hadoop3/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/maxim/.ivy2/cache\n",
      "The jars for the packages stored in: /home/maxim/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-980b4012-6e3c-4214-b6b0-65d03eb62c4b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.3.0 in central\n",
      "\tfound io.delta#delta-storage;2.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in local-m2-cache\n",
      ":: resolution report :: resolve 341ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-980b4012-6e3c-4214-b6b0-65d03eb62c4b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/7ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/08 17:17:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder.appName(\"project_ca\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars\", \"./jars/postgresql-42.5.0.jar,./jars/vertica-jdbc-9.0.0-0.jar\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+\n",
      "|Currency| Rate|  RateDate|\n",
      "+--------+-----+----------+\n",
      "|     EU |91.27|2020-01-01|\n",
      "|     EU |91.27|2020-01-02|\n",
      "|     RUB|  1.0|2020-01-01|\n",
      "|     RUB|  1.0|2020-01-02|\n",
      "|     USD|80.23|2020-01-01|\n",
      "|     USD|80.23|2020-01-02|\n",
      "+--------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"jdbc:vertica://vertica:5433/\"\n",
    "\n",
    "properties = {\"user\": \"dbadmin\", \"password\": \"\", \"database\": \"\", \"driver\": \"com.vertica.jdbc.Driver\"}\n",
    "\n",
    "df_rates = spark.read.format(\"JDBC\").options(url=url, query=\"SELECT * FROM Rate\", **properties).load()\n",
    "df_rates.printSchema()\n",
    "df_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ClientId: long (nullable = true)\n",
      " |-- ClientName: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Form: string (nullable = true)\n",
      " |-- RegisterDate: date (nullable = true)\n",
      "\n",
      "+--------+----------+----+------+------------+\n",
      "|ClientId|ClientName|Type|  Form|RegisterDate|\n",
      "+--------+----------+----+------+------------+\n",
      "|       1|  Клиент 1|   Ф|-     |  2020-11-01|\n",
      "|       2|  Клиент 2|   Ю|   ООО|  2020-11-02|\n",
      "|       3|  Клиент 3|   Ф|-     |  2020-11-03|\n",
      "|       4|  Клиент 4|   Ю|  ИП  |  2020-11-04|\n",
      "|       5|  Клиент 5|   Ф|-     |  2020-11-01|\n",
      "|       6|  Клиент 6|   Ю|  АО  |  2020-11-02|\n",
      "|       7|  Клиент 7|   Ф|-     |  2020-11-03|\n",
      "|       8|  Клиент 8|   Ю|   ПАО|  2020-11-01|\n",
      "|       9|  Клиент 9|   Ф|-     |  2020-11-02|\n",
      "|      10| Клиент 10|   Ю|   ООО|  2020-11-03|\n",
      "+--------+----------+----+------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clients = spark.read.format(\"JDBC\").options(url=url, query=\"SELECT * FROM Clients\", **properties).load()\n",
    "df_clients.printSchema()\n",
    "df_clients.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AccountID: long (nullable = true)\n",
      " |-- AccountNum: string (nullable = true)\n",
      " |-- ClientId: long (nullable = true)\n",
      " |-- DateOpen: date (nullable = true)\n",
      "\n",
      "+---------+--------------------+--------+----------+\n",
      "|AccountID|          AccountNum|ClientId|  DateOpen|\n",
      "+---------+--------------------+--------+----------+\n",
      "|        1|40702810927050000337|       1|2020-11-01|\n",
      "|        2|40802810300000009067|       2|2020-11-02|\n",
      "|        3|40802810300000009708|       3|2020-11-03|\n",
      "|        4|40802810800000030701|       4|2020-11-04|\n",
      "|        5|40802810300000011071|       5|2020-11-01|\n",
      "|        6|40802810100000063339|       6|2020-11-02|\n",
      "|        7|40702810823620000031|       7|2020-11-03|\n",
      "|        8|40802810409260005894|       8|2020-11-04|\n",
      "|        9|40802810905030000004|       9|2020-11-01|\n",
      "|       10|40802810400020001097|      10|2020-11-02|\n",
      "+---------+--------------------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_accounts = spark.read.format(\"JDBC\").options(url=url, query=\"SELECT * FROM Account\", **properties).load()\n",
    "df_accounts.printSchema()\n",
    "df_accounts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AccountDB: long (nullable = true)\n",
      " |-- AccountCR: long (nullable = true)\n",
      " |-- DateOp: date (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Currency: string (nullable = true)\n",
      " |-- Comment: string (nullable = true)\n",
      "\n",
      "+---------+---------+----------+------+--------+--------------------+\n",
      "|AccountDB|AccountCR|    DateOp|Amount|Currency|             Comment|\n",
      "+---------+---------+----------+------+--------+--------------------+\n",
      "|     5050|    10048|2020-11-02|2505.0|     EU |сигар, табачн, та...|\n",
      "|     5060|    10058|2020-11-04|2506.0|     RUB|гсм, бензин, керо...|\n",
      "|     5070|    10068|2020-11-02|2507.0|     USD|компью, монитор, ...|\n",
      "|     5080|    10078|2020-11-04|2508.0|     EU |ювелир,  юв., лом...|\n",
      "|     5090|    10088|2020-11-02|2509.0|     RUB|хоз, бытхим, подг...|\n",
      "|     5100|    10098|2020-11-04|2510.0|     USD|турусл, турист, з...|\n",
      "|     5110|    10108|2020-11-02|2511.0|     EU |торгвыруч, оплату...|\n",
      "|     5120|    10118|2020-11-04|2512.0|     RUB|а/м, ам, автомоби...|\n",
      "|     5140|    10138|2020-11-04|2514.0|     EU |сигар, табачн, та...|\n",
      "|     5150|    10148|2020-11-02|2515.0|     RUB|гсм, бензин, керо...|\n",
      "+---------+---------+----------+------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_operations = spark.read.format(\"JDBC\").options(url=url, query=\"SELECT * FROM Operation\", **properties).load()\n",
    "df_operations.printSchema()\n",
    "df_operations.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ClientId: integer (nullable = true)\n",
      " |-- ClientName: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Form: string (nullable = true)\n",
      " |-- RegisterDate: date (nullable = true)\n",
      "\n",
      "+--------+----------+----+----+------------+\n",
      "|ClientId|ClientName|Type|Form|RegisterDate|\n",
      "+--------+----------+----+----+------------+\n",
      "|       1|  Клиент 1|   Ф|   -|  2020-11-01|\n",
      "|       2|  Клиент 2|   Ю| ООО|  2020-11-02|\n",
      "|       3|  Клиент 3|   Ф|   -|  2020-11-03|\n",
      "|       4|  Клиент 4|   Ю|  ИП|  2020-11-04|\n",
      "|       5|  Клиент 5|   Ф|   -|  2020-11-01|\n",
      "|       6|  Клиент 6|   Ю|  АО|  2020-11-02|\n",
      "|       7|  Клиент 7|   Ф|   -|  2020-11-03|\n",
      "|       8|  Клиент 8|   Ю| ПАО|  2020-11-01|\n",
      "|       9|  Клиент 9|   Ф|   -|  2020-11-02|\n",
      "|      10| Клиент 10|   Ю| ООО|  2020-11-03|\n",
      "+--------+----------+----+----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"ClientId\",IntegerType(),True) \\\n",
    "      .add(\"ClientName\",StringType(),True) \\\n",
    "      .add(\"Type\",StringType(),True) \\\n",
    "      .add(\"Form\",StringType(),True) \\\n",
    "      .add(\"RegisterDate\",DateType(),True) \\\n",
    "      \n",
    "df_clients = (\n",
    "    spark.read\n",
    "        .options(delimiter=';')\n",
    "        .option(\"header\",True)\n",
    "        .schema(schema)\n",
    "        .csv(\"./data/Clients.csv\")\n",
    ")\n",
    "\n",
    "df_clients.printSchema(), df_clients.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AccountID: integer (nullable = true)\n",
      " |-- AccountNum: string (nullable = true)\n",
      " |-- ClientId: integer (nullable = true)\n",
      " |-- DateOpen: date (nullable = true)\n",
      "\n",
      "+---------+--------------------+--------+----------+\n",
      "|AccountID|          AccountNum|ClientId|  DateOpen|\n",
      "+---------+--------------------+--------+----------+\n",
      "|        1|40702810927050000337|       1|2020-11-01|\n",
      "|        2|40802810300000009067|       2|2020-11-02|\n",
      "|        3|40802810300000009708|       3|2020-11-03|\n",
      "|        4|40802810800000030701|       4|2020-11-04|\n",
      "|        5|40802810300000011071|       5|2020-11-01|\n",
      "|        6|40802810100000063339|       6|2020-11-02|\n",
      "|        7|40702810823620000031|       7|2020-11-03|\n",
      "|        8|40802810409260005894|       8|2020-11-04|\n",
      "|        9|40802810905030000004|       9|2020-11-01|\n",
      "|       10|40802810400020001097|      10|2020-11-02|\n",
      "+---------+--------------------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"AccountID\",IntegerType(),True) \\\n",
    "      .add(\"AccountNum\",StringType(),True) \\\n",
    "      .add(\"ClientId\",IntegerType(),True) \\\n",
    "      .add(\"DateOpen\",DateType(),True) \\\n",
    "      \n",
    "df_accounts = (\n",
    "    spark.read\n",
    "        .options(delimiter=';')\n",
    "        .option(\"header\",True)\n",
    "        .schema(schema)\n",
    "        .csv(\"./data/Account.csv\")\n",
    ")\n",
    "\n",
    "df_accounts.printSchema(), df_accounts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Currency: string (nullable = true)\n",
      " |-- Rate: string (nullable = true)\n",
      " |-- RateDate: date (nullable = true)\n",
      "\n",
      "+--------+-----+----------+\n",
      "|Currency| Rate|  RateDate|\n",
      "+--------+-----+----------+\n",
      "|     USD|80,23|2020-01-01|\n",
      "|      EU|91,27|2020-01-01|\n",
      "|     RUB|    1|2020-01-01|\n",
      "|     USD|80,23|2020-01-02|\n",
      "|      EU|91,27|2020-01-02|\n",
      "|     RUB|    1|2020-01-02|\n",
      "+--------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType() \\\n",
    "    .add(\"Currency\", StringType(), True) \\\n",
    "    .add(\"Rate\", StringType(), True) \\\n",
    "    .add(\"RateDate\", DateType(), True) \\\n",
    "\n",
    "df_rates = (\n",
    "    spark.read\n",
    "    .options(delimiter=';')\n",
    "    .option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(\"./data/Rate.csv\")\n",
    ")\n",
    "\n",
    "df_rates.printSchema(), df_rates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AccountDB: integer (nullable = true)\n",
      " |-- AccountCR: integer (nullable = true)\n",
      " |-- DateOp: date (nullable = true)\n",
      " |-- Amount: string (nullable = true)\n",
      " |-- Currency: string (nullable = true)\n",
      " |-- Comment: string (nullable = true)\n",
      "\n",
      "+---------+---------+----------+------+--------+--------------------+\n",
      "|AccountDB|AccountCR|    DateOp|Amount|Currency|             Comment|\n",
      "+---------+---------+----------+------+--------+--------------------+\n",
      "|        1|     4999|2020-11-01|   0,1|     RUB|а/м, а\\м, автомоб...|\n",
      "|        2|     5000|2020-11-02|   0,2|     USD| сою, соя, зерно,...|\n",
      "|        3|     5001|2020-11-03|   0,3|      EU|сигар, табачн, та...|\n",
      "|        4|     5002|2020-11-04|   0,4|     RUB|гсм, бензин, керо...|\n",
      "|        5|     5003|2020-11-01|   0,5|     USD|компью, монитор, ...|\n",
      "|        6|     5004|2020-11-02|   0,6|      EU|ювелир,  юв., лом...|\n",
      "|        7|     5005|2020-11-03|   0,7|     RUB|хоз, бытхим, подг...|\n",
      "|        8|     5006|2020-11-04|   0,8|     USD|турусл, турист, з...|\n",
      "|        9|     5007|2020-11-01|   0,9|      EU|торгвыруч, оплату...|\n",
      "|       10|     5008|2020-11-02|     1|     RUB|а/м, а\\м, автомоб...|\n",
      "+---------+---------+----------+------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType() \\\n",
    "    .add(\"AccountDB\", IntegerType(), True) \\\n",
    "    .add(\"AccountCR\", IntegerType(), True) \\\n",
    "    .add(\"DateOp\", DateType(), True) \\\n",
    "    .add(\"Amount\", StringType(), True) \\\n",
    "    .add(\"Currency\", StringType(), True) \\\n",
    "    .add(\"Comment\", StringType(), True) \\\n",
    "\n",
    "\n",
    "df_operations = (\n",
    "    spark.read\n",
    "    .options(delimiter=';')\n",
    "    .option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(\"./data/Operation.csv\")\n",
    ")\n",
    "\n",
    "df_operations.printSchema(), df_operations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка списков из postgres\n",
    "\n",
    "# url = \"jdbc:postgresql://postgres:5432/postgres\"\n",
    "# creds = {\"user\": \"postgres\", \"password\": \"myPassword\", \"driver\": \"org.postgresql.Driver\"}\n",
    "# lists = spark.read.jdbc(url, \"de_sprint.lists\", properties = creds).collect()\n",
    "\n",
    "# list1 = lists[0][1]\n",
    "# list2 = lists[1][1]\n",
    "\n",
    "# print(list1, end='\\n\\n')\n",
    "# print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для теста\n",
    "\n",
    "list1 = \"%а/м%, %а\\м%, %автомобиль %, %автомобили %, %транспорт%, %трансп%средс%, %легков%, %тягач%, %вин%, %vin%,%viн:%, %fоrd%, %форд%,%кiа%, %кия%, %киа%%мiтsuвisнi%, %мицубиси%, %нissан%, %ниссан%, %sсанiа%, %вмw%, %бмв%, %аudi%, %ауди%, %jеер%, %джип%, %vоlvо%, %вольво%, %тоyота%, %тойота%, %тоиота%, %нyuнdаi%, %хендай%, %rенаulт%, %рено%, %реugеот%, %пежо%, %lаdа%, %лада%, %dатsuн%, %додж%, %меrсеdеs%, %мерседес%, %vоlкswаgен%, %фольксваген%, %sкоdа%, %шкода%, %самосвал%, %rover%, %ровер%\"\n",
    "list2= \"%сою%, %соя%, %зерно%, %кукуруз%, %масло%, %молок%, %молоч%, %мясн%, %мясо%, %овощ%, %подсолн%, %пшениц%, %рис%, %с/х%прод%, %с/х%товар%, %с\\х%прод%, %с\\х%товар%, %сахар%, %сельск%прод%, %сельск%товар%, %сельхоз%прод%, %сельхоз%товар%, %семен%, %семечк%, %сено%, %соев%, %фрукт%, %яиц%, %ячмен%, %картоф%, %томат%, %говя%, %свин%, %курин%, %куриц%, %рыб%, %алко%, %чаи%, %кофе%, %чипс%, %напит%, %бакале%, %конфет%, %колбас%, %морож%, %с/м%, %с\\м%, %консерв%, %пищев%, %питан%, %сыр%, %макарон%, %лосос%, %треск%, %саир%, % филе%, % хек%, %хлеб%, %какао%, %кондитер%, %пиво%, %ликер%\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Currency: string (nullable = true)\n",
      " |-- RateDate: date (nullable = true)\n",
      " |-- Rate: double (nullable = true)\n",
      "\n",
      "+--------+----------+-----+\n",
      "|Currency|  RateDate| Rate|\n",
      "+--------+----------+-----+\n",
      "|      EU|2020-01-02|91.27|\n",
      "|     RUB|2020-01-02|  1.0|\n",
      "|     USD|2020-01-02|80.23|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rates = df_rates.withColumn(\"Rate\", F.regexp_replace(\"Rate\", \",\", \".\").cast(DoubleType()))\n",
    "\n",
    "df_rates = get_latest_rates(df_rates)\n",
    "\n",
    "df_rates.printSchema(), df_rates.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AccountDB: integer (nullable = true)\n",
      " |-- AccountCR: integer (nullable = true)\n",
      " |-- DateOp: date (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Comment: string (nullable = true)\n",
      "\n",
      "+---------+---------+----------+------+--------------------+\n",
      "|AccountDB|AccountCR|    DateOp|Amount|             Comment|\n",
      "+---------+---------+----------+------+--------------------+\n",
      "|        1|     4999|2020-11-01|   0.1|а/м, а\\м, автомоб...|\n",
      "|        2|     5000|2020-11-02| 16.05| сою, соя, зерно,...|\n",
      "|        3|     5001|2020-11-03| 27.38|сигар, табачн, та...|\n",
      "|        4|     5002|2020-11-04|   0.4|гсм, бензин, керо...|\n",
      "|        5|     5003|2020-11-01| 40.12|компью, монитор, ...|\n",
      "|        6|     5004|2020-11-02| 54.76|ювелир,  юв., лом...|\n",
      "|        7|     5005|2020-11-03|   0.7|хоз, бытхим, подг...|\n",
      "|        8|     5006|2020-11-04| 64.18|турусл, турист, з...|\n",
      "|        9|     5007|2020-11-01| 82.14|торгвыруч, оплату...|\n",
      "|       10|     5008|2020-11-02|   1.0|а/м, а\\м, автомоб...|\n",
      "+---------+---------+----------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_operations = df_operations.withColumn(\n",
    "    \"Amount\", F.regexp_replace(\"Amount\", \",\", \".\").cast(DoubleType()))\n",
    "\n",
    "df_operations = df_operations.join(\n",
    "    df_rates, df_operations.Currency == df_rates.Currency)\n",
    "\n",
    "# всё в рублях\n",
    "df_operations = (\n",
    "    df_operations\n",
    "    .withColumn(\"Amount\", F.round(F.col(\"Amount\") * F.col(\"Rate\"), 2))\n",
    "    .select(\"AccountDB\", \"AccountCR\", \"DateOp\", \"Amount\", \"Comment\")\n",
    ")\n",
    "\n",
    "df_operations.printSchema(), df_operations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем делать только на первую дату\n",
    "\n",
    "data_mart_date = \"2020-11-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|AccountDB|SumAmountDB|\n",
      "+---------+-----------+\n",
      "|      833|  877595.71|\n",
      "|     1645| 1283174.66|\n",
      "|     1829|  902867.22|\n",
      "|     3749|  951583.38|\n",
      "|     3997| 1345448.57|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debet =  (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .groupBy(\"AccountDB\")\n",
    "    .agg(\n",
    "        F.round(F.sum(F.col(\"Amount\")), 2).alias(\"SumAmountDB\")\n",
    "    )\n",
    ")\n",
    "\n",
    "debet.show(5), debet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|AccountCR|SumAmountCR|\n",
      "+---------+-----------+\n",
      "|     5803|  1260934.0|\n",
      "|     9427| 1356886.63|\n",
      "|    10623| 1547420.02|\n",
      "|    12027|  1595717.6|\n",
      "|    12799| 1446167.08|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 5000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit =  (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .groupBy(\"AccountCR\")\n",
    "    .agg(\n",
    "        F.round(F.sum(F.col(\"Amount\")), 2).alias(\"SumAmountCR\")\n",
    "    )\n",
    ")\n",
    "\n",
    "credit.show(5), credit.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Витрины"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Витрина corporate_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      5|2023-04-09 17:59:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|          4|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      4|2023-04-09 17:59:...|  null|    null|    MERGE|{predicate -> (ol...|null|    null|     null|          3|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      3|2023-04-09 17:25:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|          2|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      2|2023-04-09 17:25:...|  null|    null|    MERGE|{predicate -> (ol...|null|    null|     null|          1|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      1|2023-04-09 17:24:...|  null|    null|    MERGE|{predicate -> (ol...|null|    null|     null|          0|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      0|2023-04-09 17:09:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+--------------+---------+----------+----------+----------+----------+\n",
      "|AccountID|ClientId|PaymentAmt|EnrollementAmt|   TaxAmt|  ClearAmt|   CarsAmt|   FoodAmt|     FLAmt|\n",
      "+---------+--------+----------+--------------+---------+----------+----------+----------+----------+\n",
      "|        1|       1|1239646.48|           0.0|      0.0|       0.0|1239646.38|       0.0|1239646.48|\n",
      "|        2|       2|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|        3|       3|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|        4|       4|       0.0|    1698092.02|      0.0|       0.0|       0.0|1698092.02|       0.0|\n",
      "|        5|       5| 856586.88|           0.0|      0.0|       0.0| 375166.76|       0.0| 856586.88|\n",
      "|        6|       6|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|        7|       7|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|        8|       8|       0.0|    1504628.29|      0.0|1504628.29|       0.0|1504628.29|       0.0|\n",
      "|        9|       9| 1354229.6|           0.0|1354229.6|       0.0|1193697.39|       0.0| 1354229.6|\n",
      "|       10|      10|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|       11|      11|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|       12|      12|       0.0|    1110519.85|      0.0|       0.0|       0.0| 548805.55|       0.0|\n",
      "|       13|      13| 1239964.2|           0.0|1239964.2|       0.0| 1233962.9|       0.0| 1239964.2|\n",
      "|       14|      14|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|       15|      15|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|       16|      16|       0.0|     1698504.8|      0.0|       0.0|       0.0|1457678.41|       0.0|\n",
      "|       17|      17| 856891.34|           0.0|      0.0|       0.0| 854889.64|       0.0| 856891.34|\n",
      "|       18|      18|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|       19|      19|       0.0|           0.0|      0.0|       0.0|       0.0|       0.0|       0.0|\n",
      "|       20|      20|       0.0|    1504946.02|      0.0|       0.0|       0.0|1504946.02|       0.0|\n",
      "+---------+--------+----------+--------------+---------+----------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AccountId\t        ИД счета\n",
    "# ClientId\t        Ид клиента счета\n",
    "# PaymentAmt\t    Сумма операций по счету, где счет клиента указан в дебете проводки\n",
    "# EnrollementAmt\tСумма операций по счету, где счет клиента указан в кредите проводки\n",
    "# TaxAmt\t\t    Сумму операций, где счет клиента указан в дебете, и счет кредита 40702\n",
    "# ClearAmt\t        Сумма операций, где счет клиента указан в кредите, и счет дебета 40802\n",
    "# CarsAmt\t\t    Сумма операций, где счет клиента указан в дебете проводки и назначение платежа не содержит слов по маскам Списка 1\n",
    "# FoodAmt\t\t    Сумма операций, где счет клиента указан в кредите проводки и назначение платежа содержит слова по Маскам Списка 2\n",
    "# FLAmt\t\t        Сумма операций с физ. лицами. Счет клиента указан в дебете проводки, а клиент в кредите проводки – ФЛ.\n",
    "# CutoffDt\t        Дата операции;\n",
    "\n",
    "\n",
    "# Client\n",
    "#  |-- ClientId: integer (nullable = true)\n",
    "#  |-- ClientName: string (nullable = true)\n",
    "#  |-- Type: string (nullable = true)\n",
    "#  |-- Form: string (nullable = true)\n",
    "#  |-- RegisterDate: date (nullable = true)\n",
    "\n",
    "# Account\n",
    "#  |-- AccountID: integer (nullable = true)\n",
    "#  |-- AccountNum: string (nullable = true)\n",
    "#  |-- ClientId: integer (nullable = true)\n",
    "#  |-- DateOpen: date (nullable = true)\n",
    "\n",
    "# Rate\n",
    "#  |-- Currency: string (nullable = true)\n",
    "#  |-- RateDate: date (nullable = true)\n",
    "#  |-- Rate: double (nullable = true)\n",
    "\n",
    "# Operations\n",
    "#  |-- AccountDB: integer (nullable = true)\n",
    "#  |-- AccountCR: integer (nullable = true)\n",
    "#  |-- DateOp: date (nullable = true)\n",
    "#  |-- Amount: double (nullable = true)\n",
    "#  |-- Currency: string (nullable = true)\n",
    "#  |-- Comment: string (nullable = true)\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "grouped_payment = (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .join(df_accounts, df_accounts.AccountID == df_operations.AccountDB)\n",
    "    .groupBy(\"AccountDB\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"PaymentAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "grouped_tax = (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .join(df_accounts, (df_accounts.AccountID == df_operations.AccountCR) & (df_accounts.AccountNum.startswith(\"40702\")))\n",
    "    .groupBy(\"AccountDB\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"TaxAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "grouped_cars = (\n",
    "    df_operations\n",
    "    .where((df_operations.DateOp == data_mart_date) & (~reduce(lambda a, b: a | b, (df_operations.Comment.like(pat.replace(\"\\\\\", \"\\\\\\\\\")) for pat in list1.split(\",\")))))\n",
    "    .groupBy(\"AccountDB\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"CarsAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "grouped_enrollement = (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .groupBy(\"AccountCR\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"EnrollementAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "grouped_clear = (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .join(df_accounts, (df_accounts.AccountID == df_operations.AccountDB) & (df_accounts.AccountNum.startswith(\"40802\")))\n",
    "    .groupBy(\"AccountCR\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"ClearAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "grouped_food = (\n",
    "    df_operations\n",
    "    .where((df_operations.DateOp == data_mart_date) & (~reduce(lambda a, b: a | b, (df_operations.Comment.like(pat.replace(\"\\\\\", \"\\\\\\\\\")) for pat in list2.split(\",\")))))\n",
    "    .groupBy(\"AccountCR\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"FoodAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "grouped_fl = (\n",
    "    df_operations\n",
    "    .where(df_operations.DateOp == data_mart_date)\n",
    "    .join(df_accounts.alias(\"acc_db\"), F.col(\"acc_db.AccountID\") == df_operations.AccountDB)\n",
    "    .join(df_accounts.alias(\"acc_cr\"), F.col(\"acc_cr.AccountID\") == df_operations.AccountCR)\n",
    "    .join(df_clients.where(F.col(\"Type\") == \"Ф\").alias(\"cl_cr\"), F.col(\"acc_db.ClientId\") == F.col(\"cl_cr.ClientId\"))\n",
    "    .groupBy(\"AccountDB\")\n",
    "    .agg(\n",
    "        F.sum(\"Amount\").alias(\"FLAmt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "corporate_payments = (\n",
    "    df_accounts\n",
    "    .join(grouped_payment, df_accounts.AccountID == grouped_payment.AccountDB, \"left\")\n",
    "    .join(grouped_tax, df_accounts.AccountID == grouped_tax.AccountDB, \"left\")\n",
    "    .join(grouped_cars, df_accounts.AccountID == grouped_cars.AccountDB, \"left\")\n",
    "    .join(grouped_enrollement, df_accounts.AccountID == grouped_enrollement.AccountCR, \"left\")\n",
    "    .join(grouped_clear, df_accounts.AccountID == grouped_clear.AccountCR, \"left\")\n",
    "    .join(grouped_food, df_accounts.AccountID == grouped_food.AccountCR, \"left\")\n",
    "    .join(grouped_fl, df_accounts.AccountID == grouped_fl.AccountDB, \"left\")\n",
    "    .select(\"AccountID\", \"ClientId\", \n",
    "            F.when(F.col(\"PaymentAmt\").isNotNull(), F.round(F.col(\"PaymentAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"PaymentAmt\"), \n",
    "            F.when(F.col(\"EnrollementAmt\").isNotNull(), F.round(F.col(\"EnrollementAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"EnrollementAmt\"),\n",
    "            F.when(F.col(\"TaxAmt\").isNotNull(), F.round(F.col(\"TaxAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"TaxAmt\"),\n",
    "            F.when(F.col(\"ClearAmt\").isNotNull(), F.round(F.col(\"ClearAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"ClearAmt\"),\n",
    "            F.when(F.col(\"CarsAmt\").isNotNull(), F.round(F.col(\"CarsAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"CarsAmt\"),\n",
    "            F.when(F.col(\"FoodAmt\").isNotNull(), F.round(F.col(\"FoodAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"FoodAmt\"),\n",
    "            F.when(F.col(\"FLAmt\").isNotNull(), F.round(F.col(\"FLAmt\"), 2)).otherwise(F.lit(0.0)).alias(\"FLAmt\"))\n",
    ")\n",
    "\n",
    "# corporate_payments.orderBy(\"AccountID\").show()\n",
    "\n",
    "path = \"data/\" + data_mart_date + \"/corporate_payments\"\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, path)\n",
    "\n",
    "deltaTable.history().show()\n",
    "\n",
    "# deltaTable.restoreToVersion(0)\n",
    "\n",
    "(\n",
    "    deltaTable.alias(\"oldData\")\n",
    "    .merge(corporate_payments.alias(\"newData\"), \"oldData.AccountID = newData.AccountID\")\n",
    "    .whenMatchedUpdate(set={\"AccountID\": F.col(\"newData.AccountID\"),\n",
    "                            \"ClientId\": F.col(\"newData.ClientId\"),\n",
    "                            \"PaymentAmt\": F.col(\"newData.PaymentAmt\"),\n",
    "                            \"EnrollementAmt\": F.col(\"newData.EnrollementAmt\"),\n",
    "                            \"TaxAmt\": F.col(\"newData.TaxAmt\"),\n",
    "                            \"ClearAmt\": F.col(\"newData.ClearAmt\"),\n",
    "                            \"CarsAmt\": F.col(\"newData.CarsAmt\"),\n",
    "                            \"FoodAmt\": F.col(\"newData.FoodAmt\"),\n",
    "                            \"FLAmt\": F.col(\"newData.FLAmt\")}\n",
    "                       )\n",
    "    .whenNotMatchedInsert(values={\"AccountID\": F.col(\"newData.AccountID\"),\n",
    "                                  \"ClientId\": F.col(\"newData.ClientId\"),\n",
    "                                  \"PaymentAmt\": F.col(\"newData.PaymentAmt\"),\n",
    "                                  \"EnrollementAmt\": F.col(\"newData.EnrollementAmt\"),\n",
    "                                  \"TaxAmt\": F.col(\"newData.TaxAmt\"),\n",
    "                                  \"ClearAmt\": F.col(\"newData.ClearAmt\"),\n",
    "                                  \"CarsAmt\": F.col(\"newData.CarsAmt\"),\n",
    "                                  \"FoodAmt\": F.col(\"newData.FoodAmt\"),\n",
    "                                  \"FLAmt\": F.col(\"newData.FLAmt\")}\n",
    "                          )\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "corporate_payments = deltaTable.toDF()\n",
    "\n",
    "corporate_payments.orderBy(\"AccountID\").show()\n",
    "\n",
    "corporate_payments.write\\\n",
    "    .format(\"delta\")\\\n",
    "    .option(\"path\", path)\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Витрина corporate_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      6|2023-04-09 17:59:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|          5|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      5|2023-04-09 17:59:...|  null|    null|    MERGE|{predicate -> (ol...|null|    null|     null|          4|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      4|2023-04-09 17:35:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|          3|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      3|2023-04-09 17:35:...|  null|    null|    MERGE|{predicate -> (ol...|null|    null|     null|          2|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      2|2023-04-09 17:35:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|          1|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      1|2023-04-09 17:35:...|  null|    null|    MERGE|{predicate -> (ol...|null|    null|     null|          0|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      0|2023-04-09 17:09:...|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n",
      "+---------+--------------------+----------+--------+----------+----------+\n",
      "|AccountID|          AccountNum|  DateOpen|ClientId|ClientName|  TotalAmt|\n",
      "+---------+--------------------+----------+--------+----------+----------+\n",
      "|        1|40702810927050000337|2020-11-01|       1|  Клиент 1|1239646.48|\n",
      "|        4|40802810800000030701|2020-11-04|       4|  Клиент 4|1698092.02|\n",
      "|        5|40802810300000011071|2020-11-01|       5|  Клиент 5| 856586.88|\n",
      "|        8|40802810409260005894|2020-11-04|       8|  Клиент 8|1504628.29|\n",
      "|        9|40802810905030000004|2020-11-01|       9|  Клиент 9| 1354229.6|\n",
      "|       12|40702810836260000957|2020-11-04|      12| Клиент 12|1110519.85|\n",
      "|       13|40702810000000150277|2020-11-01|      13| Клиент 13| 1239964.2|\n",
      "|       16|40702810400000099734|2020-11-04|      16| Клиент 16| 1698504.8|\n",
      "|       17|40702810600000057437|2020-11-01|      17| Клиент 17| 856891.34|\n",
      "|       20|40702810473000000378|2020-11-04|      20| Клиент 20|1504946.02|\n",
      "|       21|40702810300000049813|2020-11-01|      21| Клиент 21| 1354642.4|\n",
      "|       24|40702810812250000077|2020-11-04|      24| Клиент 24|1110824.34|\n",
      "|       25|40802810327110000024|2020-11-01|      25| Клиент 25|1240281.93|\n",
      "|       28|40802810300000018362|2020-11-04|      28| Клиент 28| 1698917.6|\n",
      "|       29|40802810400020000632|2020-11-01|      29| Клиент 29| 857195.82|\n",
      "|       32|40702810400060008556|2020-11-04|      32| Клиент 32|1505263.74|\n",
      "|       33|40702810900000120462|2020-11-01|      33| Клиент 33| 1355055.2|\n",
      "|       36|40702810900000152139|2020-11-04|      36| Клиент 36| 1111128.8|\n",
      "|       37|40702810800000034454|2020-11-01|      37| Клиент 37|1240599.65|\n",
      "|       40|40702810000000113612|2020-11-04|      40| Клиент 40| 1699330.4|\n",
      "+---------+--------------------+----------+--------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AccountID\t    ИД счета\n",
    "# AccountNum\tНомер счета\n",
    "# DateOpen\t    Дата открытия счета\n",
    "# ClientId\t    ИД клиента\n",
    "# ClientName\tНаименование клиента\n",
    "# TotalAmt\t    Общая сумма оборотов по счету. Считается как сумма PaymentAmt и EnrollementAmt\n",
    "# CutoffDt\t    Дата операции\n",
    "\n",
    "total = debet.join(credit, debet.AccountDB == credit.AccountCR, \"outer\")\n",
    "total = total.na.fill(value=0, subset=[\"SumAmountDB\", \"SumAmountCR\"])\n",
    "total = total.withColumn(\"AccountID\", F.when(F.col(\"AccountDB\").isNotNull(), F.col(\"AccountDB\")).otherwise(F.col(\"AccountCR\")))\\\n",
    "    .withColumn(\"TotalAmt\", total.SumAmountDB + total.SumAmountCR)\\\n",
    "    .drop(\"AccountDB\", \"SumAmountDB\", \"AccountCR\", \"SumAmountCR\")\n",
    "total = total.join(df_accounts.alias(\"a\"), total.AccountID == df_accounts.AccountID)\\\n",
    "    .select(total.AccountID, \"ClientId\", \"TotalAmt\")\n",
    "\n",
    "# total.show()\n",
    "\n",
    "sourceDF = (\n",
    "    df_accounts\n",
    "    .join(df_clients.alias(\"c\"), df_accounts.ClientId == df_clients.ClientId)\n",
    "    .join(total.alias(\"t\"), total.AccountID == df_accounts.AccountID, \"inner\")\n",
    "    .select(df_accounts.AccountID, \"AccountNum\", \"DateOpen\", \"c.ClientId\", \"ClientName\", \"TotalAmt\")    \n",
    ")\n",
    "\n",
    "# sourceDF.show()\n",
    "\n",
    "path = \"data/\" + data_mart_date + \"/corporate_account\"\n",
    "\n",
    "targetDF = DeltaTable.forPath(spark, path)\n",
    "\n",
    "targetDF.history().show()\n",
    "\n",
    "(\n",
    "    targetDF.alias(\"oldData\")\n",
    "    .merge(sourceDF.alias(\"newData\"), \"oldData.AccountID = newData.AccountID\")\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .whenNotMatchedBySourceDelete()\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "corporate_account = targetDF.toDF()\n",
    "\n",
    "corporate_account.orderBy(\"AccountID\").show()\n",
    "\n",
    "corporate_account.write\\\n",
    "    .format(\"delta\")\\\n",
    "    .option(\"path\", path)\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Витрина corporate_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+--------+------------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|userId|userName|   operation| operationParameters| job|notebook|clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+------+--------+------------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|      4|2023-04-09 18:02:...|  null|    null|  VACUUM END|{status -> COMPLE...|null|    null|     null|          3|SnapshotIsolation|         true|{numDeletedFiles ...|        null|Apache-Spark/3.3....|\n",
      "|      3|2023-04-09 18:02:...|  null|    null|VACUUM START|{retentionCheckEn...|null|    null|     null|          2|SnapshotIsolation|         true|{numFilesToDelete...|        null|Apache-Spark/3.3....|\n",
      "|      2|2023-04-09 17:40:...|  null|    null|       WRITE|{mode -> Overwrit...|null|    null|     null|          1|     Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "|      1|2023-04-09 17:40:...|  null|    null|       MERGE|{predicate -> (ol...|null|    null|     null|          0|     Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      0|2023-04-09 17:09:...|  null|    null|       WRITE|{mode -> Overwrit...|null|    null|     null|       null|     Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n",
      "+-------+--------------------+------+--------+------------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n",
      "+------+--------------------+----+-----------+--------------------+--------------------+--------------------+----------------+--------+-----------+----------+----------------+----------------+--------------------+\n",
      "|format|                  id|name|description|            location|           createdAt|        lastModified|partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|       tableFeatures|\n",
      "+------+--------------------+----+-----------+--------------------+--------------------+--------------------+----------------+--------+-----------+----------+----------------+----------------+--------------------+\n",
      "| delta|d7643535-741a-45b...|null|       null|file:/mnt/nvme/Pr...|2023-04-09 17:09:...|2023-04-09 18:02:...|              []|       1|     114708|        {}|               1|               2|[appendOnly, inva...|\n",
      "+------+--------------------+----+-----------+--------------------+--------------------+--------------------+----------------+--------+-----------+----------+----------------+----------------+--------------------+\n",
      "\n",
      "+--------+----------+----+----+------------+----------+\n",
      "|ClientId|ClientName|Type|Form|RegisterDate|  TotalAmt|\n",
      "+--------+----------+----+----+------------+----------+\n",
      "|       1|  Клиент 1|   Ф|   -|  2020-11-01|2349861.85|\n",
      "|       3|  Клиент 3|   Ф|   -|  2020-11-03|1372137.39|\n",
      "|       4|  Клиент 4|   Ю|  ИП|  2020-11-04|1698092.02|\n",
      "|       5|  Клиент 5|   Ф|   -|  2020-11-01| 2554678.9|\n",
      "|       7|  Клиент 7|   Ф|   -|  2020-11-03| 983553.36|\n",
      "|       8|  Клиент 8|   Ю| ПАО|  2020-11-01|1504628.29|\n",
      "|       9|  Клиент 9|   Ф|   -|  2020-11-02|2858857.89|\n",
      "|      11| Клиент 11|   Ф|   -|  2020-11-04| 1526367.2|\n",
      "|      12| Клиент 12|   Ю|  ИП|  2020-11-01|1110519.85|\n",
      "|      13| Клиент 13|   Ф|   -|  2020-11-02|2350484.05|\n",
      "|      15| Клиент 15|   Ф|   -|  2020-11-01|1372455.11|\n",
      "|      16| Клиент 16|   Ю| ПАО|  2020-11-02| 1698504.8|\n",
      "|      17| Клиент 17|   Ф|   -|  2020-11-03|2555396.14|\n",
      "|      19| Клиент 19|   Ф|   -|  2020-11-01| 983857.83|\n",
      "|      20| Клиент 20|   Ю|  ИП|  2020-11-02|1504946.02|\n",
      "|      21| Клиент 21|   Ф|   -|  2020-11-03|2859588.42|\n",
      "|      23| Клиент 23|   Ф|   -|  2020-11-02| 1526780.0|\n",
      "|      24| Клиент 24|   Ю| ПАО|  2020-11-03|1110824.34|\n",
      "|      25| Клиент 25|   Ф|   -|  2020-11-04|2351106.27|\n",
      "|      27| Клиент 27|   Ф|   -|  2020-11-02|1372772.83|\n",
      "+--------+----------+----+----+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ClientId\t    ИД клиента (PK)\n",
    "# ClientName\tНаименование клиента\n",
    "# Type\t        Тип клиента (ФЛ, ЮЛ)\n",
    "# Form\t        Организационно-правовая форма (ООО, ИП и т.п.)\n",
    "# RegisterDate\tДата регистрации клиента\n",
    "# TotalAmt\t    Сумма операций по всем счетам клиент. Считается как сумма corporate_account.total_amt по всем счетам.\n",
    "# CutoffDt\t    Дата операции\n",
    "\n",
    "grouped = total.groupby(\"ClientId\").agg(F.sum(\"TotalAmt\").alias(\"TotalAmt\"))\n",
    "\n",
    "sourceDF = (\n",
    "    df_clients.join(grouped, df_clients.ClientId == grouped.ClientId)\n",
    "    .select(df_clients.ClientId, \"ClientName\", \"Type\", \"Form\", \"RegisterDate\", F.round(\"TotalAmt\", 2).alias(\"TotalAmt\"))\n",
    ")\n",
    "\n",
    "# sourceDF.show()\n",
    "\n",
    "path = \"data/\" + data_mart_date + \"/corporate_info\"\n",
    "\n",
    "targetDF = DeltaTable.forPath(spark, path)\n",
    "\n",
    "# targetDF.vacuum()\n",
    "\n",
    "targetDF.history().show()\n",
    "\n",
    "targetDF.detail().show()\n",
    "\n",
    "(\n",
    "    targetDF.alias(\"oldData\")\n",
    "    .merge(sourceDF.alias(\"newData\"), \"oldData.ClientId = newData.ClientId\")\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .whenNotMatchedBySourceDelete()\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "corporate_info = targetDF.toDF()\n",
    "\n",
    "corporate_info.orderBy(\"ClientId\").show()\n",
    "\n",
    "corporate_info.write\\\n",
    "    .format(\"delta\")\\\n",
    "    .option(\"path\", path)\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
